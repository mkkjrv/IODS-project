# RStudio exercise 4: Clustering and classification

```{r, include = FALSE}
library(MASS)
library(ggplot2)
library(GGally)
library(corrplot)
```
##Introduction to the data

In this exercise we use Boston data from MASS-library. This dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. Data includes 14 variables and 506 rows.

```{r, echo = FALSE}
dim(Boston)
str(Boston)
```

|variable|description|
|--------|-------------------------------------|
|crim|per capita crime rate by town|
|zn|proportion of residential land zoned for lots over 25,000 sq.ft.|
|indus|proportion of non-retail business acres per town|
|chas|Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)|
|nox|nitrogen oxides concentration (parts per 10 million)|
|rm|average number of rooms per dwelling|
|age|proportion of owner-occupied units built prior to 1940|
|dis|weighted mean of distances to five Boston employment centres|
|rad|index of accessibility to radial highways|
|tax|full-value property-tax rate per $10,000|
|ptratio|pupil-teacher ratio by town|
|black|1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town|
|lstat|lower status of the population (percent)|
|medv|median value of owner-occupied homes in $1000|

##Graphical overview of the data##

###Plot matrix of the data###

```{r, echo = FALSE}
pairs(Boston, col = 4)
```

There are some very intresting distributions fo variables in the plot matrix. Variable *rad* has high and low values so the plot shows that the values are consenrated either side of the plot. VAriable *   

###Plotted correlation matrix###

```{r, echo = FALSE}
#calculating the correlation matrix and correlation plot
cor_matrix <- round(cor(Boston),digits = 2)

corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)
```

Plotted correlation matrix shows that there is some high correlation between variables:

* Correlation is quite clear between industrial areas (*indus*) and nitrogen oxides (*nox*). Industry adds pollution in the area. Industry seems to correlate also with variablrs like *age*, *dis*, *ras* and *tax*.

* Nitrogen oxides (*nox*) correlations are very similar with industry (*indus*)

* Crime rate (*crim*) seems to correlate with good accessibilitty to radial highways (*rad*) and value property (*tax*).

* Old houses (*age*) and employment centers have also something common 



```{r}
summary(Boston)
```

##Scaled data##
All the variables are numerical so we can use scale()-function to scale whole data set.

```{r, echo = FALSE}
#center and standardize variables
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
```

Scaling the data makes variables look as if they are in the same range. Variables like *black* and *tax* were before scaling hundred fold compared to some other variables. 

##Creating a new categorical variable crime##

Variable *crim* is the base of the new categorical variable *crime*. 

|categories|quantile points|
|-------|-------|
|low|0%-25%|
|med_low|25%-50%|
|med_high|50%-75%|
|high|75%-100%|

```{r, echo = FALSE}
#save the scaled crim as scaled_crim
scaled_crim <- boston_scaled$crim
```

Quantile points of the variable *crim*

```{r, echo = FALSE}
#create a quantile vector of crim and print it
bins <- quantile(scaled_crim)
bins

#create a categorical variable 'crime'
crime <- cut(scaled_crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))

#look at the table of the new factor crime, do not change the actual variable "crime"
crime_tab <-table(crime)
crime_tab

#remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
summary(boston_scaled)
```

##Train and test sets##

```{r, echo = FALSE}
# number of rows in the Boston dataset 
n <- nrow(boston_scaled)

# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
ind
# create train set
train <- boston_scaled[ind,]

# create test set 
test <- boston_scaled[-ind,]
```

##Fitting the Linear Discriminant Analysis##
```{r, echo = FALSE}
#LDA = linear discriminant analysis
lda.fit <- lda(crime ~. , data = train)

#print the lda.fit object
lda.fit

#the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

#target classes as numeric
classes <- as.numeric(train$crime)
classes

#plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 3)

```


##Predicting the classes##

```{r, echo = FALSE}
#save the correct classes from test data
correct_classes <- test$crime

#remove the crime variable from test data
test <- dplyr::select(test, -crime)

#predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

#cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
```

Prediction were quite good. There was some errors in the middle of the range but classes low and especially high were good. Only one correct representative of high class was predicted to med_low class. 


